{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.7"},"colab":{"name":"PrepareDataset.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"code","metadata":{"collapsed":true,"id":"nKwx1uoINL7Q","executionInfo":{"status":"ok","timestamp":1640437037301,"user_tz":-180,"elapsed":790,"user":{"displayName":"Андрей Галичин","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06844562228736748357"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"b44768c0-e0e7-4fec-d399-5b84afa99321"},"source":["%load_ext autoreload\n","%autoreload 2"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["The autoreload extension is already loaded. To reload it, use:\n","  %reload_ext autoreload\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sHtYdOd9NOKE","executionInfo":{"status":"ok","timestamp":1640437040323,"user_tz":-180,"elapsed":2145,"user":{"displayName":"Андрей Галичин","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06844562228736748357"}},"outputId":"3a40b402-6be5-408f-959c-3d25edd84644"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","metadata":{"id":"ljXzkm28NL7U"},"source":["import os\n","from pathlib import Path\n","import shutil\n","from PIL import Image\n","import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import StratifiedKFold\n","import cv2\n","import matplotlib.pylab as plt\n","from tqdm import tqdm"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":328},"id":"SIqxQhzbNL7V","executionInfo":{"status":"ok","timestamp":1640437042036,"user_tz":-180,"elapsed":1717,"user":{"displayName":"Андрей Галичин","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06844562228736748357"}},"outputId":"d85d6a27-ef65-4102-bdb3-259f5a92010c"},"source":["# directory where train and train.csv files located (from competition data)\n","data_dir = Path('/content/drive/MyDrive/SartoriousDatasets/Initial')\n","\n","train_dir = data_dir/'train'\n","train_csv = data_dir/'train.csv'\n","\n","train_df = pd.read_csv(train_csv)\n","train_df[\"img_path\"] = train_df[\"id\"].apply(lambda x: os.path.join(train_dir, x + \".png\"))\n","tmp_df = train_df.drop_duplicates(subset=['id', 'img_path']).reset_index(drop=True)\n","tmp_df['annotation'] = train_df.groupby('id')['annotation'].agg(list).reset_index(drop=True)\n","\n","train_df = tmp_df.copy()\n","train_df.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-44bd2d6e-c10e-4aca-8608-d0ea20befd57\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>annotation</th>\n","      <th>width</th>\n","      <th>height</th>\n","      <th>cell_type</th>\n","      <th>plate_time</th>\n","      <th>sample_date</th>\n","      <th>sample_id</th>\n","      <th>elapsed_timedelta</th>\n","      <th>img_path</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0030fd0e6378</td>\n","      <td>[118145 6 118849 7 119553 8 120257 8 120961 9 ...</td>\n","      <td>704</td>\n","      <td>520</td>\n","      <td>shsy5y</td>\n","      <td>11h30m00s</td>\n","      <td>2019-06-16</td>\n","      <td>shsy5y[diff]_E10-4_Vessel-714_Ph_3</td>\n","      <td>0 days 11:30:00</td>\n","      <td>/content/drive/MyDrive/SartoriousDatasets/Init...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0140b3c8f445</td>\n","      <td>[32499 3 33201 7 33902 9 34604 10 35306 11 360...</td>\n","      <td>704</td>\n","      <td>520</td>\n","      <td>astro</td>\n","      <td>09h00m00s</td>\n","      <td>2020-09-13</td>\n","      <td>astros[cereb]_F8-3_Vessel-361_Ph_4</td>\n","      <td>0 days 09:00:00</td>\n","      <td>/content/drive/MyDrive/SartoriousDatasets/Init...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>01ae5a43a2ab</td>\n","      <td>[241026 3 241726 9 242427 13 243130 14 243834 ...</td>\n","      <td>704</td>\n","      <td>520</td>\n","      <td>cort</td>\n","      <td>13h30m00s</td>\n","      <td>2020-11-04</td>\n","      <td>cort[oka-high]_B5-1_Vessel-377_Ph_1</td>\n","      <td>0 days 13:30:00</td>\n","      <td>/content/drive/MyDrive/SartoriousDatasets/Init...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>026b3c2c4b32</td>\n","      <td>[170753 5 171454 12 172158 13 172862 13 173565...</td>\n","      <td>704</td>\n","      <td>520</td>\n","      <td>cort</td>\n","      <td>19h30m00s</td>\n","      <td>2020-11-04</td>\n","      <td>cort[oka-low]_H6-2_Vessel-377_Ph_2</td>\n","      <td>0 days 19:30:00</td>\n","      <td>/content/drive/MyDrive/SartoriousDatasets/Init...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>029e5b3b89c7</td>\n","      <td>[139142 7 139845 10 140548 13 141251 15 141955...</td>\n","      <td>704</td>\n","      <td>520</td>\n","      <td>cort</td>\n","      <td>13h30m00s</td>\n","      <td>2020-10-27</td>\n","      <td>cort[pre-treat]_B8-2_Vessel-377_Ph_2</td>\n","      <td>0 days 13:30:00</td>\n","      <td>/content/drive/MyDrive/SartoriousDatasets/Init...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-44bd2d6e-c10e-4aca-8608-d0ea20befd57')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-44bd2d6e-c10e-4aca-8608-d0ea20befd57 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-44bd2d6e-c10e-4aca-8608-d0ea20befd57');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["             id  ...                                           img_path\n","0  0030fd0e6378  ...  /content/drive/MyDrive/SartoriousDatasets/Init...\n","1  0140b3c8f445  ...  /content/drive/MyDrive/SartoriousDatasets/Init...\n","2  01ae5a43a2ab  ...  /content/drive/MyDrive/SartoriousDatasets/Init...\n","3  026b3c2c4b32  ...  /content/drive/MyDrive/SartoriousDatasets/Init...\n","4  029e5b3b89c7  ...  /content/drive/MyDrive/SartoriousDatasets/Init...\n","\n","[5 rows x 10 columns]"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":347},"id":"rnqwIC__NL7V","executionInfo":{"status":"ok","timestamp":1640437042037,"user_tz":-180,"elapsed":14,"user":{"displayName":"Андрей Галичин","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06844562228736748357"}},"outputId":"e86d6f05-e37a-4f59-cae1-600ad477039a"},"source":["# !!! Run this cell with split=True only ones to determinate KFold split (otherwise set split = False)\n","\n","split = False\n","\n","# Split initial set on 5 folds stratified by cell type. Each fold will containt ~ 120 samples.\n","# Keep 1 fold for validation purposes\n","\n","if split:\n","    skf = StratifiedKFold(n_splits=5, shuffle=True)\n","    \n","    for fold, (_, val_idx) in enumerate(skf.split(X=train_df, y=train_df['cell_type']), 1):\n","        train_df.loc[val_idx, 'fold'] = fold\n","    train_df['fold'] = train_df['fold'].astype(np.uint8)\n","    \n","    # save id-to-fold dataset\n","    train_df[['id', 'fold']].to_csv('/content/drive/MyDrive/SartoriousDatasets/id_to_fold.csv', index=False)\n","else:\n","    id_to_fold = pd.read_csv('/content/drive/MyDrive/SartoriousDatasets/id_to_fold.csv')\n","\n","    train_df = train_df.merge(right=id_to_fold, how='left', on='id')\n","\n","print(train_df.shape)  # must be (606, 11)\n","train_df.head()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(606, 11)\n"]},{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-980b6f43-1fcf-4c59-8cc8-8d8daa41cb6b\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>annotation</th>\n","      <th>width</th>\n","      <th>height</th>\n","      <th>cell_type</th>\n","      <th>plate_time</th>\n","      <th>sample_date</th>\n","      <th>sample_id</th>\n","      <th>elapsed_timedelta</th>\n","      <th>img_path</th>\n","      <th>fold</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0030fd0e6378</td>\n","      <td>[118145 6 118849 7 119553 8 120257 8 120961 9 ...</td>\n","      <td>704</td>\n","      <td>520</td>\n","      <td>shsy5y</td>\n","      <td>11h30m00s</td>\n","      <td>2019-06-16</td>\n","      <td>shsy5y[diff]_E10-4_Vessel-714_Ph_3</td>\n","      <td>0 days 11:30:00</td>\n","      <td>/content/drive/MyDrive/SartoriousDatasets/Init...</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0140b3c8f445</td>\n","      <td>[32499 3 33201 7 33902 9 34604 10 35306 11 360...</td>\n","      <td>704</td>\n","      <td>520</td>\n","      <td>astro</td>\n","      <td>09h00m00s</td>\n","      <td>2020-09-13</td>\n","      <td>astros[cereb]_F8-3_Vessel-361_Ph_4</td>\n","      <td>0 days 09:00:00</td>\n","      <td>/content/drive/MyDrive/SartoriousDatasets/Init...</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>01ae5a43a2ab</td>\n","      <td>[241026 3 241726 9 242427 13 243130 14 243834 ...</td>\n","      <td>704</td>\n","      <td>520</td>\n","      <td>cort</td>\n","      <td>13h30m00s</td>\n","      <td>2020-11-04</td>\n","      <td>cort[oka-high]_B5-1_Vessel-377_Ph_1</td>\n","      <td>0 days 13:30:00</td>\n","      <td>/content/drive/MyDrive/SartoriousDatasets/Init...</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>026b3c2c4b32</td>\n","      <td>[170753 5 171454 12 172158 13 172862 13 173565...</td>\n","      <td>704</td>\n","      <td>520</td>\n","      <td>cort</td>\n","      <td>19h30m00s</td>\n","      <td>2020-11-04</td>\n","      <td>cort[oka-low]_H6-2_Vessel-377_Ph_2</td>\n","      <td>0 days 19:30:00</td>\n","      <td>/content/drive/MyDrive/SartoriousDatasets/Init...</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>029e5b3b89c7</td>\n","      <td>[139142 7 139845 10 140548 13 141251 15 141955...</td>\n","      <td>704</td>\n","      <td>520</td>\n","      <td>cort</td>\n","      <td>13h30m00s</td>\n","      <td>2020-10-27</td>\n","      <td>cort[pre-treat]_B8-2_Vessel-377_Ph_2</td>\n","      <td>0 days 13:30:00</td>\n","      <td>/content/drive/MyDrive/SartoriousDatasets/Init...</td>\n","      <td>5</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-980b6f43-1fcf-4c59-8cc8-8d8daa41cb6b')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-980b6f43-1fcf-4c59-8cc8-8d8daa41cb6b button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-980b6f43-1fcf-4c59-8cc8-8d8daa41cb6b');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["             id  ... fold\n","0  0030fd0e6378  ...    5\n","1  0140b3c8f445  ...    4\n","2  01ae5a43a2ab  ...    5\n","3  026b3c2c4b32  ...    3\n","4  029e5b3b89c7  ...    5\n","\n","[5 rows x 11 columns]"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","metadata":{"id":"YS-D5n2WNL7W"},"source":["def rle_decode(mask_rle, shape):\n","    \n","    s = mask_rle.split()\n","    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n","    starts -= 1\n","    ends = starts + lengths\n","    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n","    for lo, hi in zip(starts, ends):\n","        img[lo:hi] = 1\n","    return img.reshape(shape)\n","\n","\n","def get_mask(annotation, width, height, binary_mask=False):\n","    dtype = np.uint8 if binary_mask else np.uint16\n","    \n","    img_mask = np.zeros((height, width), dtype=dtype)\n","    for i, annot in enumerate(annotation):\n","        fill_value = 1 if binary_mask else i + 1\n","        img_mask = np.where(rle_decode(annot, (height, width)) != 0, fill_value, img_mask)\n","    \n","    return img_mask\n","\n","  \n","def get_mask_w_intersection(mask, contour, annotation, width, height):\n","    # TODO: Overlapping cells will be involved too\n","    img_mask = np.zeros((height, width), dtype=np.uint8)\n","\n","    for annot in annotation:\n","        cell_mask = rle_decode(annot, (height, width))\n","        img_mask += cell_mask\n","\n","    img_mask = np.clip(img_mask, 0, 2)  # convert int. of > 2 cells in 1 cls\n","\n","    intersection = np.where(img_mask == 2, 1, 0)\n","    intersection = np.where((intersection == 1) & (contour == 1), 1, 0).astype(np.uint8)\n","\n","    final_mask = mask + intersection\n","    \n","    return final_mask\n","\n","\n","def extract_contour(mask):\n","    labels = np.unique(mask)[1:]  # exclude background\n","    \n","    contours = np.full_like(mask, fill_value=0., dtype=np.uint8)\n","    \n","    for label in labels:\n","        mask_l = np.where(mask == label, 1, 0).astype(np.uint8)\n","        contours_l, _ = cv2.findContours(mask_l, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n","        cv2.drawContours(contours, contours_l, -1, (1, 0, 0))\n","        \n","    return contours"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uUXWgvBDNL7X"},"source":["def create_masks(dataset, mask_dir,\n","                 mask_type='binary', subtract_contour=False):\n","    \n","    stem_dict = {\n","        'binary': 'mask',\n","        'mask_w_contour': 'mask_w_contour',\n","        'categorical_intersection': 'categorical_intersection',\n","        'categorical': 'categorical_mask'\n","    }\n","    \n","    if not os.path.exists(mask_dir):\n","        os.mkdir(mask_dir)\n","        \n","    mask_stem = stem_dict.get(mask_type, 'mask')  # binary masks by default\n","    \n","    for _, (path, annot, width, height) in tqdm(dataset[['img_path', 'annotation', 'width', 'height']].iterrows()):\n","        stem = Path(path).stem\n","        \n","        mask = get_mask(annot, width, height, binary_mask=True)\n","\n","        if mask_type != 'binary' and mask_type != 'mask_w_intersection':\n","            instance_mask = get_mask(annot, width, height, binary_mask=False)\n","            contour = extract_contour(instance_mask)\n","        \n","        if mask_type == 'mask_w_contour':\n","            if subtract_contour:\n","                mask = mask - contour\n","            final_mask = np.stack([mask, contour], axis=-1)  # [H, W, 2]\n","        elif mask_type == 'categorical_intersection':\n","            final_mask = get_mask_w_intersection(mask, contour, annot, width, height)\n","        elif mask_type == 'categorical':\n","            final_mask = mask + contour\n","        else:\n","            final_mask = mask\n","        \n","        mask_path = Path(mask_dir)/(stem + '_' + mask_stem + '.tif')\n","        \n","        Image.fromarray(final_mask).save(mask_path)\n","\n","        \n","def create_images(dataset, image_dir):\n","    \n","    if not os.path.exists(image_dir):\n","        os.mkdir(image_dir)\n","        \n","    for _, (path, annot, width, height) in tqdm(dataset[['img_path', 'annotation', 'width', 'height']].iterrows()):\n","        stem = Path(path).stem    \n","        \n","        image_path = Path(image_dir)/(stem + '.png')\n","        \n","        shutil.copy(path, image_path)\n","\n","\n","def create_instances(dataset, instance_dir):\n","    \n","    if not os.path.exists(instance_dir):\n","        os.mkdir(instance_dir)\n","        \n","    for _, (path, annot, width, height) in tqdm(dataset[['img_path', 'annotation', 'width', 'height']].iterrows()):\n","        stem = Path(path).stem\n","        \n","        instance_mask = get_mask(annot, width, height, binary_mask=False)\n","        \n","        instance_path = Path(instance_dir)/(stem + '_' + 'instance' + '.tif')\n","        \n","        Image.fromarray(instance_mask).save(instance_path)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AQUXwtrnNL7Y","executionInfo":{"status":"ok","timestamp":1639254216586,"user_tz":-180,"elapsed":233463,"user":{"displayName":"Андрей Галичин","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06844562228736748357"}},"outputId":"539445b1-1749-4814-a88d-f3200f4e67de"},"source":["# dir where to store all extracted data\n","data_dir = Path('/content/drive/MyDrive/SartoriousDatasets/supervised')\n","\n","train_dir = data_dir/'train'\n","val_dir = data_dir/'val'\n","\n","split_train_df = train_df[train_df.fold != 5]\n","split_val_df = train_df[train_df.fold == 5]\n","\n","if not os.path.exists(train_dir):\n","    os.makedirs(train_dir)\n","    os.makedirs(val_dir)\n","    \n","# create train and validation images\n","# create_images(\n","#     split_train_df, train_dir/'images')\n","# create_images(\n","#     split_val_df, val_dir/'images')\n","\n","# create train and validation binary masks\n","# create_masks(\n","#     split_train_df, train_dir/'masks', mask_type='binary')\n","# create_masks(\n","#     split_val_df, val_dir/'masks', mask_type='binary')\n","\n","# # create train and validation 2-channel masks (mask + contour)\n","# create_masks(\n","#     split_train_df, train_dir/'masks_w_contours', mask_type='mask_w_contour')\n","# create_masks(\n","#     split_val_df, val_dir/'masks_w_contours', mask_type='mask_w_contour')\n","\n","# # create train and validation categorical masks(bg = 0; binary mask = 1; contour = 2)\n","# create_masks(\n","#     split_train_df, train_dir/'categorical', mask_type='categorical')\n","# create_masks(\n","#     split_val_df, val_dir/'categorical', mask_type='categorical')\n","\n","# create train and validation multiclass masks (mask + intersections (overlay masks included))\n","create_masks(\n","    split_train_df, train_dir/'categorical_intersection', mask_type='categorical_intersection')\n","create_masks(\n","    split_val_df, val_dir/'categorical_intersection', mask_type='categorical_intersection')\n","\n","# # create train and validation instance masks\n","# create_instances(\n","#     split_train_df, train_dir/'instances')\n","# create_instances(\n","#     split_val_df, val_dir/'instances')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["485it [03:08,  2.58it/s]\n","121it [00:45,  2.67it/s]\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WjEakcXJNL7Z","executionInfo":{"status":"ok","timestamp":1638703421643,"user_tz":-180,"elapsed":210883,"user":{"displayName":"Андрей Галичин","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06844562228736748357"}},"outputId":"7b6e1c09-6f19-428d-ee57-c968631ef11e"},"source":["# create full masks data (for submission train). Images take from downloaded 'train' directory\n","submission_dir = Path('/content/drive/MyDrive/SartoriousDatasets/Initial')\n","\n","mask_dir = submission_dir/'train_masks'\n","\n","if not os.path.exists(mask_dir):\n","    os.makedirs(mask_dir)\n","\n","create_masks(\n","    train_df, mask_dir, mask_type='mask_w_contour')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["606it [03:30,  2.88it/s]\n"]}]},{"cell_type":"markdown","source":["### Extract intersection based on data science bowl 2018 top-1 solution"],"metadata":{"id":"-wKYnqsbEHxP"}},{"cell_type":"code","source":["from skimage.morphology import square, dilation\n","from skimage.segmentation import watershed\n","from skimage import measure"],"metadata":{"id":"8WF5kGGnC8Hn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def extract_dsb2018_mask(labels):\n","    tmp = dilation(labels > 0, square(9))  \n","    tmp2 = watershed(tmp, labels, mask=tmp, watershed_line=True) > 0\n","    tmp = tmp ^ tmp2\n","    tmp = dilation(tmp, square(7))\n","\n","    props = measure.regionprops(labels)\n","    msk0 = (labels > 0)\n","    msk0 = msk0.astype('uint8')\n","\n","    msk1 = np.zeros_like(labels, dtype='bool')\n","\n","    max_area = np.max([p.area for p in props])\n","\n","    for y0 in range(labels.shape[0]):\n","        for x0 in range(labels.shape[1]):\n","            if not tmp[y0, x0]:\n","                continue\n","            if labels[y0, x0] == 0:\n","                if max_area > 4000:\n","                    sz = 6\n","                else:\n","                    sz = 3\n","            else:\n","                sz = 3\n","                try:\n","                    if props[labels[y0, x0] - 1].area < 300:\n","                        sz = 1\n","                    elif props[labels[y0, x0] - 1].area < 2000:\n","                        sz = 2\n","                except:\n","                    print(f'Label {labels[y0, x0]} was not found by region proposal. Assuming its size is too small')\n","                    sz = 1\n","            uniq = np.unique(labels[max(0, y0-sz):min(labels.shape[0], y0+sz+1), max(0, x0-sz):min(labels.shape[1], x0+sz+1)])\n","            if len(uniq[uniq > 0]) > 1:\n","                msk1[y0, x0] = True\n","                msk0[y0, x0] = 0\n","\n","    msk1 = msk1.astype('uint8')\n","\n","    msk = np.stack([msk0, msk1])\n","    msk = np.rollaxis(msk, 0, 3)\n","\n","    return msk\n","\n","\n","def extract_dsb2018_mask_v2(labels):\n","    tmp = dilation(labels > 0, square(9))  \n","    tmp2 = watershed(tmp, labels, mask=tmp)\n","    \n","    intersection = np.full_like(tmp2, fill_value=0., dtype=np.uint8)\n","\n","    tmp2_labels = np.unique(tmp2)[1:]  # no bg\n","\n","    for lbl in tmp2_labels:\n","        mask_l = np.where(tmp2 == lbl, 1, 0).astype(np.uint8)\n","        contours_l, _ = cv2.findContours(mask_l, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n","        cv2.drawContours(intersection, contours_l, -1, (1, 0, 0))\n","\n","    tmp = intersection.copy()\n","    tmp = dilation(tmp, square(7))\n","\n","    props = measure.regionprops(labels)\n","    msk0 = (labels > 0)\n","    msk0 = msk0.astype('uint8')\n","\n","    msk1 = np.zeros_like(labels, dtype='bool')\n","\n","    max_area = np.max([p.area for p in props])\n","\n","    for y0 in range(labels.shape[0]):\n","        for x0 in range(labels.shape[1]):\n","            if not tmp[y0, x0]:\n","                continue\n","            if labels[y0, x0] == 0:\n","                if max_area > 4000:\n","                    sz = 6\n","                else:\n","                    sz = 3\n","            else:\n","                sz = 3\n","                try:\n","                    if props[labels[y0, x0] - 1].area < 300:\n","                        sz = 1\n","                    elif props[labels[y0, x0] - 1].area < 2000:\n","                        sz = 2\n","                except:\n","                    print(f'Label {labels[y0, x0]} was not found by region proposal. Assuming its size is too small')\n","                    sz = 1\n","            uniq = np.unique(labels[max(0, y0-sz):min(labels.shape[0], y0+sz+1), max(0, x0-sz):min(labels.shape[1], x0+sz+1)])\n","            if len(uniq[uniq > 0]) > 1:\n","                msk1[y0, x0] = True\n","                msk0[y0, x0] = 0\n","\n","    msk1 = msk1.astype('uint8')\n","\n","    msk = np.stack([msk0, msk1])\n","    msk = np.rollaxis(msk, 0, 3)\n","\n","    return msk"],"metadata":{"id":"oTQmDu_lETyy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data_dir = Path('/content/drive/MyDrive/SartoriousDatasets/supervised')\n","\n","train_dir = data_dir/'train'\n","val_dir = data_dir/'val'\n","\n","split_train_df = train_df[train_df.fold != 5]\n","split_val_df = train_df[train_df.fold == 5]\n","\n","def save_dsb2018_masks(dataset, save_dir, v2=False):\n","  if not os.path.exists(save_dir):\n","      os.makedirs(save_dir)\n","\n","  for _, (path, annot, width, height) in tqdm(dataset[['img_path', 'annotation', 'width', 'height']].iterrows()):\n","      stem = Path(path).stem\n","      \n","      instance_mask = get_mask(annot, width, height, binary_mask=False)\n","\n","      if v2:\n","        dsb2018_mask = extract_dsb2018_mask_v2(instance_mask)\n","      else:\n","        dsb2018_mask = extract_dsb2018_mask(instance_mask)\n","\n","      dsb2018_path = Path(save_dir)/(stem + '_' + 'dsb2018_mask' + '.tif')\n","\n","      Image.fromarray(dsb2018_mask).save(dsb2018_path)\n","\n","\n","save_dsb2018_masks(split_train_df, train_dir/'dsb2018_masks_v2', v2=True)\n","save_dsb2018_masks(split_val_df, val_dir/'dsb2018_masks_v2', v2=True)"],"metadata":{"id":"jW-f0qypGMfS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"ouN3Gei1v5_y"},"execution_count":null,"outputs":[]}]}