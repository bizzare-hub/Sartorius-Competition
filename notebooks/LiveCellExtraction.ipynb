{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"YO90kxPTsbZv"},"outputs":[],"source":["%load_ext autoreload\n","%autoreload 2"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"E_Se8CzesbZz"},"outputs":[],"source":["from pathlib import Path\n","import os\n","import cv2\n","from PIL import Image\n","import json\n","import math\n","import numpy as np\n","import matplotlib.pylab as plt\n","from matplotlib.path import Path as mpPath\n","from tqdm import tqdm"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TdmfS5MysbZ0"},"outputs":[],"source":["import joblib\n","from joblib import Parallel, delayed\n","import contextlib"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"r4p-gedRwCde","executionInfo":{"status":"ok","timestamp":1639298088632,"user_tz":-180,"elapsed":18441,"user":{"displayName":"Андрей Галичин","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06844562228736748357"}},"outputId":"497e0d3d-bc43-44ac-e4fa-6fabc6b9a9d2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qPOHp6mRsbZ0"},"outputs":[],"source":["@contextlib.contextmanager\n","def tqdm_joblib(tqdm_object):\n","    class TqdmBatchCompletionCallBack(joblib.parallel.BatchCompletionCallBack):\n","        def __init__(self, *args, **kwargs):\n","            super().__init__(*args, **kwargs)\n","            \n","        def __call__(self, *args, **kwargs):\n","            tqdm_object.update(n=self.batch_size)\n","            return super().__call__(*args, **kwargs)\n","        \n","    old_batch_callback = joblib.parallel.BatchCompletionCallBack\n","    joblib.parallel.BatchCompletionCallBack = TqdmBatchCompletionCallBack\n","    \n","    try:\n","        yield tqdm_object\n","    finally:\n","        joblib.parallel.BatchCompletionCallBack = old_batch_callback\n","        tqdm_object.close()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0topNzZZsbZ1"},"outputs":[],"source":["def create_cell_dict(path):\n","    with open(path) as f:\n","        data = json.load(f)\n","        \n","    ids = list()\n","    for i, img_dict in enumerate(data['images']):\n","        ids.append(data['images'][i]['id'])\n","        \n","    d = {k: {'segmentation': [], 'bbox': [], 'path': []} for k in ids}\n","    \n","    for i in range(len(d)):\n","        d[data['images'][i]['id']]['path'].append(data['images'][i]['file_name'])\n","        \n","    for key in data['annotations'].keys():\n","        img_id = data['annotations'][key]['image_id']\n","        seg = data['annotations'][key]['segmentation'][0]\n","        bbox = data['annotations'][key]['bbox']\n","        \n","        d[img_id]['segmentation'].append(seg)\n","        d[img_id]['bbox'].append(bbox)\n","    \n","    return d\n","\n","\n","def get_cell_mask(raw_segmentation, binary_mask=True):\n","    dtype = np.uint8 if binary_mask else np.uint16\n","    array = np.zeros((520, 704), dtype=dtype)\n","    \n","    for lbl, cell_mask in enumerate(raw_segmentation, 1):\n","        x = cell_mask[0::2]\n","        y = cell_mask[1::2]\n","        \n","        arr = [(x, y) for (x, y) in zip(y, x)]\n","        vertices = np.asarray(arr)\n","        path = mpPath(vertices)\n","        x, y = np.mgrid[:520, :704]\n","        \n","        # mesh grid to a list of points\n","        points = np.vstack([x.ravel(), y.ravel()]).T\n","        \n","        # select points included in the path\n","        mask = path.contains_points(points)\n","        \n","        if not binary_mask:\n","            mask = np.where(mask, lbl, 0)\n","        \n","        img_mask = mask.reshape(x.shape).astype(dtype)\n","        array += img_mask\n","        \n","    if binary_mask:\n","        array = np.clip(array, 0, 1)  # could there be values < 0 or > 1 ?\n","        \n","    return array\n","\n","\n","def get_cell_contour(raw_segmentation):\n","    mask = get_cell_mask(raw_segmentation, binary_mask=False)\n","    \n","    labels = np.unique(mask)[1:]  # exclude background\n","    \n","    contours = np.full_like(mask, fill_value=0., dtype=np.uint8)\n","    \n","    for label in labels:\n","        mask_l = np.where(mask == label, 1, 0).astype(np.uint8)\n","        contours_l, _ = cv2.findContours(mask_l, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n","        cv2.drawContours(contours, contours_l, -1, (1, 0, 0))\n","    \n","    return contours"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cQqX4COnsbZ2"},"outputs":[],"source":["def extract_image_data(data_dir, data):\n","    images = []\n","    images_names = []\n","    \n","    for key in data.keys():\n","        image_stem = data[key]['path'][0]\n","        image_path = str(Path(data_dir)/image_stem)\n","        image = np.array(Image.open(image_path))\n","        \n","        images.append(image)\n","        images_names.append(image_path)\n","        \n","    images = np.stack(images)\n","    \n","    return images, images_names\n","\n","\n","def extract_mask_data(data_dir, data, binary_mask=True, parallel=False, n_jobs=1):\n","    masks = []\n","    masks_names = [str(Path(data_dir)/data[key]['path'][0])\n","                   for key in data.keys()]\n","    \n","    if parallel:\n","        n_total = len(data)\n","        \n","        with tqdm_joblib(tqdm(desc='Livecell masks extraction', total=n_total)) as progress_bar:\n","            worker = Parallel(n_jobs=n_jobs, backend='loky')\n","            masks = worker(delayed(get_cell_mask)(data[key]['segmentation'], binary_mask=binary_mask)\n","                           for key in data.keys())\n","    else:\n","        for key in data.keys():\n","            raw_segmentation = data[key]['segmentation']\n","            mask = get_cell_mask(raw_segmentation, binary_mask=binary_mask)\n","            \n","            masks.append(mask)\n","    \n","    masks = np.stack(masks)\n","    \n","    return masks, masks_names\n","\n","\n","def extract_contour_data(data, parallel=False, n_jobs=1):\n","    contours = []\n","    \n","    if parallel:\n","        n_total = len(data)\n","        \n","        with tqdm_joblib(tqdm(desc='Livecell contours extraction', total=n_total)) as progress_bar:\n","            worker = Parallel(n_jobs=n_jobs, backend='loky')\n","            contours = worker(delayed(get_cell_contour)(data[key]['segmentation'])\n","                           for key in data.keys())\n","    else:\n","        for key in data.keys():\n","            raw_segmentation = data[key]['segmentation']\n","            contour = get_cell_mask(raw_segmentation)\n","            \n","            contours.append(contour)\n","    \n","    contours = np.stack(contours)\n","    \n","    return contours"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jeHA-XEksbZ3","executionInfo":{"status":"ok","timestamp":1639298097774,"user_tz":-180,"elapsed":804,"user":{"displayName":"Андрей Галичин","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06844562228736748357"}},"outputId":"e190ac79-88a3-4ac9-9c79-6f8bdd8329d6"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[PosixPath('/content/drive/MyDrive/SartoriousDatasets/LiveCell/LIVECell_single_cells/shsy5y')]"]},"metadata":{},"execution_count":8}],"source":["# PATH to LiveCell_dataset_2021 directory\n","data_dir = Path('/content/drive/MyDrive/SartoriousDatasets/LiveCell')\n","\n","image_dir = data_dir/'images'\n","annotation_dir = data_dir/'LIVECell_single_cells'\n","\n","annotation_cell_dirs = sorted(list(annotation_dir.glob('*')))\n","annotation_cell_dirs[:3]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HwdYfpojsbZ4"},"outputs":[],"source":["def create_dirs(save_dir):\n","    \n","    save_dir_train, save_dir_val, save_dir_test = save_dir/'train', save_dir/'val', save_dir/'test'\n","    list_save_dirs = [save_dir_train, save_dir_val, save_dir_test]\n","    \n","    # creating all directories\n","    if not os.path.exists(save_dir_train):\n","        os.makedirs(save_dir_train)\n","        os.makedirs(save_dir_val)\n","        os.makedirs(save_dir_test)\n","        \n","        [os.mkdir(d/'images') for d in list_save_dirs]\n","        # [os.mkdir(d/'masks') for d in list_save_dirs]\n","        \n","# Directory where to save parsed images and masks\n","save_dir = Path('/content/drive/MyDrive/SartoriousDatasets/LiveCell')\n","\n","create_dirs(save_dir)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LSZzmJmXsbZ5"},"outputs":[],"source":["def parse_livecell_images(annotation_cell_dirs, save_dir, cell_dict):\n","    \n","    for cell_dir in annotation_cell_dirs:\n","        cell_split_paths = sorted(list(cell_dir.glob('*.json')))  # train|val|test\n","        \n","        cell_name = cell_dict[str(cell_dir.stem)]  # A172, BT474 etc.\n","        \n","        for split_path in cell_split_paths:\n","            data = create_cell_dict(split_path)\n","            \n","            split_name = str(split_path.stem).split('_')[-1]  # train|val|test\n","            \n","            if split_name == 'train' or split_name == 'val':\n","                data_image_dir = image_dir/'livecell_train_val_images'/cell_name\n","            elif split_name == 'test':\n","                data_image_dir = image_dir/'livecell_test_images'/cell_name\n","            else:\n","                raise ValueError(f\"Split name not known: {split_name}\")\n","            \n","            images, images_names = extract_image_data(data_image_dir, data)\n","            \n","            # to be sure dtype is okay\n","            images = images.astype(np.uint8)\n","            \n","            cur_save_dir = save_dir/split_name/'images'\n","            \n","            for idx in range(images.shape[0]):\n","                img_name = images_names[idx]\n","                \n","                img_save_path = cur_save_dir/(str(Path(img_name).stem) + '.png')\n","                \n","                Image.fromarray(images[idx]).save(img_save_path)\n","                \n","\n","def parse_livecell_masks(annotation_cell_dirs, save_dir, cell_dict,\n","                         mask_dir_name='masks', mask_type='binary',\n","                         parallel=True, n_jobs=1):\n","    \n","    stem_dict = {\n","        'binary': 'mask',\n","        'mask_w_contour': 'mask_w_contour',\n","        'categorical': 'categorical_mask'\n","    }\n","    \n","    mask_stem = stem_dict.get(mask_type, 'mask')  # binary masks by default\n","    \n","    for cell_dir in annotation_cell_dirs:\n","        cell_split_paths = sorted(list(cell_dir.glob('*.json')))  # train|val|test\n","        \n","        cell_name = cell_dict[str(cell_dir.stem)]  # A172, BT474 etc.\n","        \n","        for split_path in cell_split_paths:\n","            data = create_cell_dict(split_path)\n","            \n","            split_name = str(split_path.stem).split('_')[-1]  # train|val|test\n","            \n","            if split_name == 'train' or split_name == 'val':\n","                data_image_dir = image_dir/'livecell_train_val_images'/cell_name\n","            elif split_name == 'test':\n","                data_image_dir = image_dir/'livecell_test_images'/cell_name\n","            else:\n","                raise ValueError(f\"Split name not known: {split_name}\")\n","        \n","            masks, masks_names = extract_mask_data(\n","                data_image_dir, data, binary_mask=True, parallel=parallel, n_jobs=n_jobs)\n","            \n","            if mask_type == 'mask_w_contour':\n","                contours = extract_contour_data(data, parallel=parallel, n_jobs=n_jobs)\n","                final_masks = np.stack([masks, contours], axis=-1)  # extend masks with contours: [N, H, W, 2]\n","            elif mask_type == 'categorical':\n","                contours = extract_contour_data(data, parallel=parallel, n_jobs=n_jobs)\n","                final_masks = masks + contours\n","            elif mask_type == 'binary':\n","                final_masks = masks\n","            else:\n","                raise ValueError()\n","            \n","            cur_save_dir = save_dir/split_name/mask_dir_name\n","\n","            if not os.path.exists(cur_save_dir):\n","                os.makedirs(cur_save_dir)\n","            \n","            for idx in range(final_masks.shape[0]):\n","                mask_name = masks_names[idx]\n","                \n","                mask_save_path = cur_save_dir/(str(Path(mask_name).stem) + '_' + mask_stem + '.tif')\n","                \n","                Image.fromarray(final_masks[idx]).save(mask_save_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"id4p9do2sbZ6"},"outputs":[],"source":["cell_dict = {\n","    'a172': 'A172',\n","    'bt474': 'BT474',\n","    'bv2': 'BV2',\n","    'huh7': 'Huh7',\n","    'mcf7': 'MCF7',\n","    'ratc6': 'RatC6',\n","    'shsy5y': 'SHSY5Y',\n","    'skbr3': 'SkBr3',\n","    'skov3': 'SKOV3'\n","}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jmFQWsDQsbZ6"},"outputs":[],"source":["parse_livecell_images(annotation_cell_dirs, save_dir, cell_dict)"]},{"cell_type":"code","source":["parse_livecell_masks(annotation_cell_dirs, save_dir, cell_dict,\n","                     mask_dir_name='masks_w_contours', mask_type='mask_w_contour', n_jobs=4)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lejWM_ICw949","executionInfo":{"status":"ok","timestamp":1639312442547,"user_tz":-180,"elapsed":14177735,"user":{"displayName":"Андрей Галичин","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06844562228736748357"}},"outputId":"15a9e3d3-e7b1-46bb-9086-db95de0149bd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Livecell masks extraction: 100%|██████████| 449/449 [1:36:05<00:00, 12.84s/it]\n","Livecell contours extraction: 100%|██████████| 449/449 [1:44:36<00:00, 13.98s/it]\n","Livecell masks extraction: 100%|██████████| 79/79 [16:59<00:00, 12.91s/it]\n","Livecell contours extraction: 100%|██████████| 79/79 [18:13<00:00, 13.85s/it]\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"wlCB6Zatz731"},"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.7"},"colab":{"name":"LiveCellExtraction.ipynb","provenance":[]}},"nbformat":4,"nbformat_minor":0}